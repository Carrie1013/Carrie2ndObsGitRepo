### Fine Tune
- 神经网络：微调![[Pasted image 20231026111233.png]]
- Train:
	- 目标数据集上的正常训练任务，但使用更强的正则化
		- 使用更小的学习率
		- 使用更少的数据迭代
		- 源数据集远复杂于目标数据时通常微调效果更好
	- 固定一些层（如微调时不改变底层参数，尤其是在源数据不够复杂时，可防止微调导致的过拟合）
		- 神经网络通常学习有层次的特征表示
		- 低层次的特征更加通用，高层次的特征更与数据集相关
		- 固定底部参数，起到更强的正则效果


### LLM Fine Tune
- 定义相关性 for rank top3
- 用数据finetune
	- 直接GPT
	- embedding + 相似rank top3
- 14日志

1. 对比百川和GPT4对媒资生成的标签的质量： https://github.com/baichuan-inc/Baichuan-13B

参考列表：[浪漫,心动,期待,失落,心痛,幸福,怀旧,温馨,憧憬,失望,嫉妒,自省,感慨,希冀,羡慕,淡然,悸动,恍惚,忐忑,感动,回忆,好奇,震惊,兴奋,害怕,紧张,担忧,迷惑,困惑,心酸,悲壮,同情,骄傲,恐惧,无助,壮志,哀思,背叛,难过,挣扎,荣耀,冷静,沉痛,敬意,反思,愤怒,冷酷,遗憾,沉重,振奋,警醒,惋惜,冲突,审慎,颤栗,焦虑,欢乐]
目标电影：战狼2
输出：情感/基调
维度：积极，中性，消极

1.请参照参考列表，根据电影主要传达的情感，从不同维度分别为电影生成一个标签。
2.重复上述操作6次；
3.为步骤1和步骤2生成的每一个标签判断与电影核心内容的符合程度，输出符合程度为‘高，中，低’。
4.筛选符合程度为‘高’的标签。
5.分别为筛选后的标签进行排序，每个维度选出最多前三的标签。
6.根据电影主要传达的情感，分别判断是否每一个维度，输出‘保留’或者‘不保留’。
7.如果步骤6中，需要同时保留两种及以上维度，输出维度占比(总和100%)。
8.针对步骤7中的标签，如果参考列表中有相似标签，请使用候选列表中的标签；如果候选列表中没有相似词汇，且属于情感/基调的标签，请输出需要增加的标签并加入到候选列表中。
9.整合所有需要保留的维度标签，对标签打分（十分制）。
10.输出最终需要保留的维度和其占比, 不同维度下的标签及得分，返回json格式。格式参考{ “积极”: “”,”中性: “”,”消极”: "","积极标签": {}, 中性标签": {}, "消极标签": {}}
11.输出最终的标签列表,返回json格式。


### Embedding模型
- 模型：embeddings = OpenAIEmbeddings(
    deployment="embedding-ada-002-2",
    model="text-embedding-ada-002",