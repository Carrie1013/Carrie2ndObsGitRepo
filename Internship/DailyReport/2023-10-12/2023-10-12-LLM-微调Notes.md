1. 调用openai-api接口：
```
import openai
openai.api_key="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"
# token名：TCL_Carr1
openai.ChatCompletion.create(
	model="gpt-4",
	messages=[
		{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Who won the world series in 2020?"}, {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
		{"role": "user", "content": "Where was it played?"}
] )
```
- role：有效值为"system", "user", "assistant"
- system：指示API如何行为，基本上它是OpenAI的主要提示
- user：想问的问题，是单个或多个对话中的用户输入，可以是多行文本
- assistant：编写一段对话时，需要使用这个角色来附加响应，以便API记住讨论的内容
1. 示例： https://zhuanlan.zhihu.com/p/611077743
2. 示例：精调GPT#1：精调GPT-3进行文本分类的最佳实践 https://zhuanlan.zhihu.com/p/628944148
3. 示例：LLM实战系列(1)—强强联合Langchain-Vicuna应用实战 https://zhuanlan.zhihu.com/p/628750042

### 接口调用须知：
- 收费标准： https://openai.com/pricing
- TCL服务器token： http://10.101.100.4:18889/?token=1b859dbceaf072c1bcfc86bd19665c306fcade958e36256e
- 可用模型： https://platform.openai.com/docs/models
- OpenAI教程： https://platform.openai.com/docs/api-reference/introduction
- 我的API-keys： https://platform.openai.com/account/api-keys
### 大模型常见下游处理工作：
1. **微调 (Fine-Tuning)**：
    - 使用特定任务的小型数据集对预训练模型进行微调，使其更好地适应这个任务。例如，使用 GPT 模型进行文本分类、情感分析等。
2. **模型裁剪 (Model Pruning)**：
    - 删除模型中的某些参数或层，以减少模型的大小和计算需求，同时尽量保持模型的性能。
3. **模型量化 (Model Quantization)**：
    - 将模型参数从32位浮点数转换为较低位宽（如8位）的整数，以减少模型大小和提高推理速度。
4. **模型蒸馏 (Model Distillation)**：
    - 使用一个大模型来指导一个小模型的训练，使小模型尽量接近大模型的性能。
5. **模型部署**：
    - 将模型部署到特定的平台或设备上，如云服务器、移动设备、IoT 设备等。
6. **模型解释 (Model Interpretability)**：
    - 使用各种工具和技术来理解和解释模型的决策过程。
7. **模型评估和监控**：
    - 在真实世界的数据上定期评估模型的性能，并监控模型的行为以确保其正常运行。
8. **数据后处理**：
    - 在模型产生输出后，可能需要进一步的处理来满足特定应用的需求，如文本生成的后处理、图像处理等。
9. **模型更新和维护**：
    - 根据新的数据或反馈，定期更新和优化模型。

